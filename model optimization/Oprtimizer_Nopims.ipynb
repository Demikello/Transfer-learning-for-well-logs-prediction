{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWldRsWAEIb6"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import random as rd\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, Dense, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "x-qocK47EUot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_taranaki = pd.read_csv('/content/drive/MyDrive/Taranaki_PEF_clear.csv')\n",
        "df_nopims = pd.read_csv('/content/drive/MyDrive/NOPIMS_clear.csv')"
      ],
      "metadata": {
        "id": "hK8FCxL9EUrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_taranaki = df_taranaki.rename(columns={'WELLNAME': 'UWI', 'DENS': 'RHOB'})"
      ],
      "metadata": {
        "id": "M8sKj5oDEUtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_taranaki.set_index(['UWI', 'DEPT'], inplace = True)\n",
        "df_nopims.set_index(['UWI', 'DEPT'], inplace = True)"
      ],
      "metadata": {
        "id": "hb20bP6rEUwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_taranaki = df_taranaki[['RHOB', 'DRHO', 'GR', 'PEF']]\n",
        "df_nopims = df_nopims[['RHOB', 'DRHO', 'GR', 'PEF']]"
      ],
      "metadata": {
        "id": "3CdPYr8xEaHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Количество скважин Taranaki = {df_taranaki.index.get_level_values(0).nunique()}')\n",
        "print(f'Количество скважин Nopims = {df_nopims.index.get_level_values(0).nunique()}')"
      ],
      "metadata": {
        "id": "81mQmRBCEaJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_taranaki = df_taranaki.drop(['PEF'], axis = 1)\n",
        "y_taranaki = df_taranaki['PEF']\n",
        "\n",
        "X_nopims = df_nopims.drop(['PEF'], axis = 1)\n",
        "y_nopims = df_nopims['PEF']"
      ],
      "metadata": {
        "id": "IAbavrizEU4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_X = pd.concat([X_taranaki, X_nopims])\n",
        "df_y = pd.concat([y_taranaki, y_nopims])"
      ],
      "metadata": {
        "id": "-ubWzGCKEfAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_X.reset_index()\n",
        "y = df_y.reset_index()\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "normalized_values_X = scaler_X.fit_transform(X[['RHOB', 'DRHO', 'GR']])\n",
        "normalized_values_y = scaler_y.fit_transform(y[['PEF']])\n",
        "\n",
        "X[['RHOB', 'DRHO', 'GR']] = normalized_values_X\n",
        "y[['PEF']] = normalized_values_y\n",
        "\n",
        "X_scaled = X.set_index(['UWI', 'DEPT'])\n",
        "y_scaled = y.set_index(['UWI', 'DEPT'])"
      ],
      "metadata": {
        "id": "yZDiSX6pEfCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_nopims = X_scaled.loc[X_nopims.index.get_level_values(0).unique()]\n",
        "y_nopims = y_scaled.loc[y_nopims.index.get_level_values(0).unique()]"
      ],
      "metadata": {
        "id": "RN-F8-PJEfEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_part_size = 0.7"
      ],
      "metadata": {
        "id": "PkAu1J5TEjBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd.seed(12)\n",
        "train_wells_nopims = rd.sample(\n",
        "    X_nopims.index.get_level_values(0).unique().tolist(),\n",
        "    round(len(X_nopims.index.get_level_values(0).unique()) * train_part_size),\n",
        ")\n",
        "\n",
        "val_test_wells_nopims = list(set(X_nopims.index.get_level_values(0).unique().tolist()) - set(train_wells_nopims))\n",
        "val_test_wells_nopims = sorted(val_test_wells_nopims)\n",
        "rd.shuffle(val_test_wells_nopims)\n",
        "\n",
        "rd.seed(12)\n",
        "val_wells_nopims = rd.sample(\n",
        "    val_test_wells_nopims,\n",
        "    round(len(val_test_wells_nopims) * 0.5),)\n",
        "\n",
        "test_wells_nopims = list(set(val_test_wells_nopims) - set(val_wells_nopims))\n",
        "test_wells_nopims = sorted(test_wells_nopims)\n",
        "rd.shuffle(test_wells_nopims)"
      ],
      "metadata": {
        "id": "RXagj1YDEjDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X_nopims = X_nopims.loc[train_wells_nopims]\n",
        "train_y_nopims = y_nopims.loc[train_wells_nopims]\n",
        "\n",
        "val_X_nopims = X_nopims.loc[val_wells_nopims]\n",
        "val_y_nopims = y_nopims.loc[val_wells_nopims]\n",
        "\n",
        "test_X_nopims = X_nopims.loc[test_wells_nopims]\n",
        "test_y_nopims = y_nopims.loc[test_wells_nopims]"
      ],
      "metadata": {
        "id": "l6tKz0hkEl8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_data_per_well(features, target, time_steps=50):\n",
        "    Xs, ys = [], []\n",
        "\n",
        "    # Перебираем уникальные значения скважин\n",
        "    for well_name in features.index.get_level_values('UWI').unique():\n",
        "        # Получаем данные для текущей скважины\n",
        "        well_features = features.xs(well_name, level='UWI')\n",
        "        well_target = target.xs(well_name, level='UWI')\n",
        "\n",
        "        # Генерируем X и y для текущей скважины\n",
        "        for i in range(len(well_features) - time_steps):\n",
        "            Xs.append(well_features.iloc[i:i + time_steps].values)\n",
        "            ys.append(well_target.iloc[i + time_steps - 1])\n",
        "\n",
        "    return np.array(Xs), np.array(ys)"
      ],
      "metadata": {
        "id": "1l1_i2w_El-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X_nopims, train_y_nopims = gen_data_per_well(train_X_nopims, train_y_nopims)\n",
        "val_X_nopims, val_y_nopims = gen_data_per_well(val_X_nopims, val_y_nopims)\n",
        "test_X_nopims, test_y_nopims = gen_data_per_well(test_X_nopims, test_y_nopims)"
      ],
      "metadata": {
        "id": "wBtCELoiEmAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(trial):\n",
        "    model = Sequential()\n",
        "    input_shape = (None, 3)\n",
        "    # Подбор гиперпараметров для сверточных слоев\n",
        "    for i in range(trial.suggest_int('conv_layers', 1, 5)):  # Количество сверточных слоев\n",
        "        filters = trial.suggest_categorical('filters_' + str(i), [32, 64, 128, 256])\n",
        "        kernel_size = trial.suggest_categorical('kernel_size_' + str(i), [2, 3, 5])\n",
        "\n",
        "        model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', input_shape=input_shape))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Подбор гиперпараметров для LSTM слоев\n",
        "    for j in range(trial.suggest_int('lstm_layers', 1, 5)):  # Количество LSTM слоев\n",
        "        lstm_units = trial.suggest_categorical('lstm_units_' + str(j), [32, 64, 128, 256])\n",
        "        model.add(LSTM(lstm_units, activation='relu', return_sequences=True))\n",
        "        model.add(Dropout(trial.suggest_float('dropout_' + str(j), 0.01, 0.3)))\n",
        "\n",
        "    # Полносвязный слой\n",
        "    model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "    # Подбор гиперпараметров для оптимизатора\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-7, 1e-3)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Функция для оценки модели\n",
        "def objective(trial):\n",
        "    model = create_model(trial)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256, 512])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "    model.fit(train_X_nopims, train_y_nopims,\n",
        "              validation_data=(val_X_nopims, val_y_nopims),\n",
        "              epochs=20,\n",
        "              batch_size=batch_size,\n",
        "              callbacks=[early_stopping],\n",
        "              verbose=0)\n",
        "\n",
        "    # Оценка модели на тренировочных данных\n",
        "    y_pred = model.predict(test_X_nopims)\n",
        "    r2 = r2_score(test_y_nopims, y_pred)\n",
        "\n",
        "    return r2\n",
        "\n",
        "# Запуск подбора гиперпараметров\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "id": "9uNH0EwJEsT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
        "print(\"Лучшее значение R^2:\", study.best_value)"
      ],
      "metadata": {
        "id": "qvffeTToEsWT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
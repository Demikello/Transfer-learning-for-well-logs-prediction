{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlWp79NuTkvO",
        "outputId": "d212ff6a-5005-4dc1-b05d-5413c6cf22bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import random as rd\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, Dense, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "um9IZm5pTLJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yG-O1AvSJdT",
        "outputId": "bb6fc568-737b-4cb5-e016-01225a5bb509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_kansas = pd.read_csv('/content/drive/MyDrive/Kansas_ILD_clear.csv')\n",
        "df_spe = pd.read_csv('/content/drive/MyDrive/SPE_clear.csv')"
      ],
      "metadata": {
        "id": "6fq670i5SG3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_kansas.set_index(['UWI', 'DEPT'], inplace = True)\n",
        "df_spe.set_index(['UWI', 'DEPT'], inplace = True)"
      ],
      "metadata": {
        "id": "rsyIXoizSG6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_kansas = df_kansas[['GR', 'NPHI', 'ILD', 'DPHI']]\n",
        "df_spe = df_spe[['GR', 'NPHI', 'ILD', 'DPHI']]"
      ],
      "metadata": {
        "id": "VFRvYXibSG8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Количество скважин Kansas = {df_kansas.index.get_level_values(0).nunique()}')\n",
        "print(f'Количество скважин SPE = {df_spe.index.get_level_values(0).nunique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iieBtSdkSG-7",
        "outputId": "698a120c-77b5-4c67-c4e7-0c4158e2ebca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество скважин Kansas = 96\n",
            "Количество скважин SPE = 72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_kansas = df_kansas.drop('DPHI', axis = 1)\n",
        "y_kansas = df_kansas['DPHI']\n",
        "\n",
        "X_spe = df_spe.drop(['DPHI'], axis = 1)\n",
        "y_spe = df_spe['DPHI']"
      ],
      "metadata": {
        "id": "-gMSQC3vSHBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_X = pd.concat([X_kansas, X_spe])\n",
        "df_y = pd.concat([y_kansas, y_spe])"
      ],
      "metadata": {
        "id": "7JoaBDMdSUg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_X.reset_index()\n",
        "y = df_y.reset_index()\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "normalized_values_X = scaler_X.fit_transform(X[['GR', 'NPHI', 'ILD']])\n",
        "normalized_values_y = scaler_y.fit_transform(y[['DPHI']])\n",
        "\n",
        "X[['GR', 'NPHI', 'ILD']] = normalized_values_X\n",
        "y[['DPHI']] = normalized_values_y\n",
        "\n",
        "X_scaled = X.set_index(['UWI', 'DEPT'])\n",
        "y_scaled = y.set_index(['UWI', 'DEPT'])"
      ],
      "metadata": {
        "id": "FBndyJ4ySUjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_spe = X_scaled.loc[X_spe.index.get_level_values(0).unique()]\n",
        "y_spe = y_scaled.loc[y_spe.index.get_level_values(0).unique()]"
      ],
      "metadata": {
        "id": "QA53lx2dSHDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_part_size = 0.7\n",
        "\n",
        "rd.seed(10)\n",
        "train_wells_spe = rd.sample(\n",
        "    X_spe.index.get_level_values(0).unique().tolist(),\n",
        "    round(len(X_spe.index.get_level_values(0).unique()) * train_part_size),\n",
        ")\n",
        "\n",
        "val_test_wells_spe = list(set(X_spe.index.get_level_values(0).unique().tolist()) - set(train_wells_spe))\n",
        "val_test_wells_spe = sorted(val_test_wells_spe)\n",
        "rd.shuffle(val_test_wells_spe)\n",
        "\n",
        "rd.seed(10)\n",
        "val_wells_spe = rd.sample(\n",
        "    val_test_wells_spe,\n",
        "    round(len(val_test_wells_spe) * 0.5),)\n",
        "\n",
        "test_wells_spe = list(set(val_test_wells_spe) - set(val_wells_spe))\n",
        "test_wells_spe = sorted(test_wells_spe)\n",
        "rd.shuffle(test_wells_spe)"
      ],
      "metadata": {
        "id": "flecEL9BSZKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X_spe = X_spe.loc[train_wells_spe]\n",
        "train_y_spe = y_spe.loc[train_wells_spe]\n",
        "\n",
        "val_X_spe = X_spe.loc[val_wells_spe]\n",
        "val_y_spe = y_spe.loc[val_wells_spe]\n",
        "\n",
        "test_X_spe = X_spe.loc[test_wells_spe]\n",
        "test_y_spe = y_spe.loc[test_wells_spe]"
      ],
      "metadata": {
        "id": "rA447tOKSdNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_data_per_well(features, target, time_steps=30):\n",
        "    Xs, ys = [], []\n",
        "\n",
        "    # Перебираем уникальные значения скважин\n",
        "    for well_name in features.index.get_level_values('UWI').unique():\n",
        "        # Получаем данные для текущей скважины\n",
        "        well_features = features.xs(well_name, level='UWI')\n",
        "        well_target = target.xs(well_name, level='UWI')\n",
        "\n",
        "        # Генерируем X и y для текущей скважины\n",
        "        for i in range(len(well_features) - time_steps):\n",
        "            Xs.append(well_features.iloc[i:i + time_steps].values)\n",
        "            ys.append(well_target.iloc[i + time_steps - 1])\n",
        "\n",
        "    return np.array(Xs), np.array(ys)"
      ],
      "metadata": {
        "id": "XiTNtFj_SdPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X_spe, train_y_spe = gen_data_per_well(train_X_spe, train_y_spe)\n",
        "val_X_spe, val_y_spe = gen_data_per_well(val_X_spe, val_y_spe)\n",
        "test_X_spe, test_y_spe = gen_data_per_well(test_X_spe, test_y_spe)"
      ],
      "metadata": {
        "id": "HJw5oV1pSdRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(trial):\n",
        "    model = Sequential()\n",
        "    input_shape = (None, 3)\n",
        "    # Подбор гиперпараметров для сверточных слоев\n",
        "    for i in range(trial.suggest_int('conv_layers', 1, 5)):  # Количество сверточных слоев\n",
        "        filters = trial.suggest_categorical('filters_' + str(i), [32, 64, 128, 256])\n",
        "        kernel_size = trial.suggest_categorical('kernel_size_' + str(i), [2, 3, 5])\n",
        "\n",
        "        model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', input_shape=input_shape))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Подбор гиперпараметров для LSTM слоев\n",
        "    for j in range(trial.suggest_int('lstm_layers', 1, 5)):  # Количество LSTM слоев\n",
        "        lstm_units = trial.suggest_categorical('lstm_units_' + str(j), [32, 64, 128, 256])\n",
        "        model.add(LSTM(lstm_units, activation='relu', return_sequences=True))\n",
        "        model.add(Dropout(trial.suggest_float('dropout_' + str(j), 0.01, 0.3)))\n",
        "\n",
        "    # Полносвязный слой\n",
        "    model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "    # Подбор гиперпараметров для оптимизатора\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-7, 1e-3)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Функция для оценки модели\n",
        "def objective(trial):\n",
        "    model = create_model(trial)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "    model.fit(train_X_spe, train_y_spe,\n",
        "              validation_data=(val_X_spe, val_y_spe),\n",
        "              epochs=20,\n",
        "              batch_size=batch_size,\n",
        "              callbacks=[early_stopping],\n",
        "              verbose=0)\n",
        "\n",
        "    # Оценка модели на тренировочных данных\n",
        "    y_pred = model.predict(test_X_spe)\n",
        "    r2 = r2_score(test_y_spe, y_pred)\n",
        "\n",
        "    return r2\n",
        "\n",
        "# Запуск подбора гиперпараметров\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "id": "OPmPXPZ3WhR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Лучшие гиперпараметры:\", study.best_params)\n",
        "print(\"Лучшее значение R^2:\", study.best_value)"
      ],
      "metadata": {
        "id": "SatM_BaoVXCW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}